{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6K9TQeP8Xvv9USmJHpabn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL_AcL88Xv2r"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRjcFg97aqly"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Nl7b8_C3vdG8",
        "outputId": "da79617c-dc2f-4886-844b-81c5f876c1ad"
      },
      "source": [
        "#DATASET SOURCE FROM https://github.com/dbrehmer/Knowself/blob/master/data/mypersonality/essays.csv\"\n",
        "#DATASET USED IN THIS NOTEBOOK IS DATASET FROM THE SOURCE THAT HAS BEEN TRANSLATED TO BAHASA INDONESIA USING GOOGLE TRANSLATE\n",
        "\n",
        "DATASET_URL = \"https://raw.githubusercontent.com/lazuardi100/Hexa-Engineer/ML/Dataset/dataset.csv\"\n",
        "df = pd.read_csv(DATASET_URL, sep =',')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#AUTHID</th>\n",
              "      <th>TTEXT</th>\n",
              "      <th>cEXT</th>\n",
              "      <th>cNEU</th>\n",
              "      <th>cAGR</th>\n",
              "      <th>cCON</th>\n",
              "      <th>cOPN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1997_504851.txt</td>\n",
              "      <td>Nah, sekarang saya baru saja bangun dari tidur...</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1997_605191.txt</td>\n",
              "      <td>Nah, di sini kita pergi dengan arus kesadaran ...</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1997_687252.txt</td>\n",
              "      <td>Keyboard terbuka dan tombol untuk mendorong. H...</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1997_568848.txt</td>\n",
              "      <td>Aku tidak percaya itu! Ini benar-benar terjadi...</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1997_688160.txt</td>\n",
              "      <td>Nah, di sini aku pergi dengan aliran tua yang ...</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           #AUTHID                                              TTEXT  ... cCON cOPN\n",
              "0  1997_504851.txt  Nah, sekarang saya baru saja bangun dari tidur...  ...    n    y\n",
              "1  1997_605191.txt  Nah, di sini kita pergi dengan arus kesadaran ...  ...    n    n\n",
              "2  1997_687252.txt  Keyboard terbuka dan tombol untuk mendorong. H...  ...    y    y\n",
              "3  1997_568848.txt  Aku tidak percaya itu! Ini benar-benar terjadi...  ...    y    n\n",
              "4  1997_688160.txt  Nah, di sini aku pergi dengan aliran tua yang ...  ...    n    y\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSa84m-fWk-m",
        "outputId": "83631cbc-f7e4-4ea0-d1b8-e2ac901d7b62"
      },
      "source": [
        "def changeLabel(labels):\n",
        "  for index, values in enumerate(labels.values):\n",
        "    if values == 'n':\n",
        "      labels[index] = 0\n",
        "    else:\n",
        "      labels[index] = 1\n",
        "  return labels\n",
        "\n",
        "changeLabel(df['cEXT'])\n",
        "changeLabel(df['cNEU'])\n",
        "changeLabel(df['cAGR'])\n",
        "changeLabel(df['cCON'])\n",
        "changeLabel(df['cOPN'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       1\n",
              "3       0\n",
              "4       1\n",
              "       ..\n",
              "2462    0\n",
              "2463    1\n",
              "2464    0\n",
              "2465    1\n",
              "2466    1\n",
              "Name: cOPN, Length: 2467, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ETSRWdeh74v"
      },
      "source": [
        "train_dataset, val_dataset, test_dataset = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpCdmoNPasJD"
      },
      "source": [
        "train_data = train_dataset['TTEXT']\n",
        "train_label_ext  = train_dataset['cEXT']\n",
        "train_label_neu  = train_dataset['cNEU']\n",
        "train_label_agr  = train_dataset['cAGR']\n",
        "train_label_con  = train_dataset['cCON']\n",
        "train_label_opn  = train_dataset['cOPN']\n",
        "\n",
        "val_data = val_dataset['TTEXT']\n",
        "val_label_ext  = val_dataset['cEXT']\n",
        "val_label_neu  = val_dataset['cNEU']\n",
        "val_label_agr  = val_dataset['cAGR']\n",
        "val_label_con  = val_dataset['cCON']\n",
        "val_label_opn  = val_dataset['cOPN']\n",
        "\n",
        "test_data = test_dataset['TTEXT']\n",
        "test_label_ext  = test_dataset['cEXT']\n",
        "test_label_neu  = test_dataset['cNEU']\n",
        "test_label_agr  = test_dataset['cAGR']\n",
        "test_label_con  = test_dataset['cCON']\n",
        "test_label_opn  = test_dataset['cOPN']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FmqfVpRvbVo"
      },
      "source": [
        "train_dataset_ext = tf.data.Dataset.from_tensor_slices((train_data.values, train_label_ext.values.astype(dtype=np.float32)))\n",
        "train_dataset_neu = tf.data.Dataset.from_tensor_slices((train_data.values, train_label_neu.values.astype(dtype=np.float32)))\n",
        "train_dataset_agr = tf.data.Dataset.from_tensor_slices((train_data.values, train_label_agr.values.astype(dtype=np.float32)))\n",
        "train_dataset_con = tf.data.Dataset.from_tensor_slices((train_data.values, train_label_con.values.astype(dtype=np.float32)))\n",
        "train_dataset_opn = tf.data.Dataset.from_tensor_slices((train_data.values, train_label_opn.values.astype(dtype=np.float32)))\n",
        "\n",
        "val_dataset_ext = tf.data.Dataset.from_tensor_slices((val_data.values, val_label_ext.values.astype(dtype=np.float32)))\n",
        "val_dataset_neu = tf.data.Dataset.from_tensor_slices((val_data.values, val_label_neu.values.astype(dtype=np.float32)))\n",
        "val_dataset_agr = tf.data.Dataset.from_tensor_slices((val_data.values, val_label_agr.values.astype(dtype=np.float32)))\n",
        "val_dataset_con = tf.data.Dataset.from_tensor_slices((val_data.values, val_label_con.values.astype(dtype=np.float32)))\n",
        "val_dataset_opn = tf.data.Dataset.from_tensor_slices((val_data.values, val_label_opn.values.astype(dtype=np.float32)))\n",
        "\n",
        "test_dataset_ext = tf.data.Dataset.from_tensor_slices((test_data.values, test_label_ext.values.astype(dtype=np.float32)))\n",
        "test_dataset_neu = tf.data.Dataset.from_tensor_slices((test_data.values, test_label_neu.values.astype(dtype=np.float32)))\n",
        "test_dataset_agr = tf.data.Dataset.from_tensor_slices((test_data.values, test_label_agr.values.astype(dtype=np.float32)))\n",
        "test_dataset_con = tf.data.Dataset.from_tensor_slices((test_data.values, test_label_con.values.astype(dtype=np.float32)))\n",
        "test_dataset_opn = tf.data.Dataset.from_tensor_slices((test_data.values, test_label_opn.values.astype(dtype=np.float32)))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Jp5BGiJnR9"
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/nnlm-id-dim128/2\"\n",
        "\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
        "\n",
        "model_ext = tf.keras.Sequential([\n",
        "        hub_layer,\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv_v-4e-TORd"
      },
      "source": [
        "batch_size = 512\n",
        "num_examples = tf.data.experimental.cardinality(train_dataset_ext).numpy()\n",
        "ext_batches = train_dataset_ext.shuffle(num_examples // 4).batch(batch_size).prefetch(1)\n",
        "val_batches = val_dataset_ext.batch(batch_size).prefetch(1)\n",
        "test_batches = test_dataset_ext.batch(batch_size)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4G3sVX9Tzur",
        "outputId": "6e435e5a-6721-404c-8bae-d71009adbe9b"
      },
      "source": [
        "model_ext.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model_ext.fit(ext_batches,\n",
        "                        validation_data=val_batches,\n",
        "                        epochs=20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.4733 - accuracy: 0.8751 - val_loss: 0.6997 - val_accuracy: 0.5425\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.4567 - accuracy: 0.8932 - val_loss: 0.6316 - val_accuracy: 0.6518\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.4326 - accuracy: 0.8858 - val_loss: 0.6432 - val_accuracy: 0.6437\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.4061 - accuracy: 0.9407 - val_loss: 0.6572 - val_accuracy: 0.6194\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.3855 - accuracy: 0.9545 - val_loss: 0.6305 - val_accuracy: 0.6478\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.3645 - accuracy: 0.9513 - val_loss: 0.6526 - val_accuracy: 0.6316\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.3440 - accuracy: 0.9662 - val_loss: 0.6414 - val_accuracy: 0.6437\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.3197 - accuracy: 0.9742 - val_loss: 0.6385 - val_accuracy: 0.6478\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.3011 - accuracy: 0.9789 - val_loss: 0.6480 - val_accuracy: 0.6275\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.2782 - accuracy: 0.9796 - val_loss: 0.6405 - val_accuracy: 0.6599\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.2532 - accuracy: 0.9826 - val_loss: 0.6613 - val_accuracy: 0.6275\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.2335 - accuracy: 0.9897 - val_loss: 0.6509 - val_accuracy: 0.6518\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.2116 - accuracy: 0.9870 - val_loss: 0.6591 - val_accuracy: 0.6478\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1909 - accuracy: 0.9919 - val_loss: 0.6613 - val_accuracy: 0.6478\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1720 - accuracy: 0.9933 - val_loss: 0.6773 - val_accuracy: 0.6235\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1535 - accuracy: 0.9958 - val_loss: 0.6712 - val_accuracy: 0.6397\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1344 - accuracy: 0.9980 - val_loss: 0.6903 - val_accuracy: 0.6235\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1183 - accuracy: 0.9993 - val_loss: 0.6869 - val_accuracy: 0.6275\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.1046 - accuracy: 0.9995 - val_loss: 0.7106 - val_accuracy: 0.6194\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 5s 1s/step - loss: 0.0922 - accuracy: 0.9995 - val_loss: 0.7101 - val_accuracy: 0.6235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjUlkXTNT6QW"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}